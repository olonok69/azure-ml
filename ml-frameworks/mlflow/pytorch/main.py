# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/ml-frameworks/using-mlflow/train-and-deploy-pytorch/train-and-deploy-pytorch.ipynb
# Use MLflow with Azure Machine Learning to Train and Deploy PyTorch Image Classifier

# Check core SDK version number
import azureml.core
from azureml.telemetry import set_diagnostics_collection
from azureml.core.workspace import Workspace
from azureml.core.compute import ComputeTarget, AmlCompute
from azureml.core.compute_target import ComputeTargetException
import shutil
from azureml.core import Experiment, Environment, ScriptRunConfig
import sys, os
import mlflow
import mlflow.azureml

import azureml.core
from azureml.core import Workspace
import json
from mlflow.deployments import get_deploy_client

print("SDK version:", azureml.core.VERSION)
print("MLflow version:", mlflow.version.VERSION)

ws = Workspace.from_config()
ws.get_details()

print('Workspace name: ' + ws.name, 
      'Azure region: ' + ws.location, 
      'Subscription id: ' + ws.subscription_id, 
      'Resource group: ' + ws.resource_group, sep = '\n')

mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())

# choose a name for your cluster
cluster_name = "gpu-cluster"

try:
    compute_target = ComputeTarget(workspace=ws, name=cluster_name)
    print('Found existing compute target')
except ComputeTargetException:
    print('Creating a new compute target...')
    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', 
                                                           max_nodes=1)

    # create the cluster
    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)

    compute_target.wait_for_completion(show_output=True)

# use get_status() to get a detailed status for the current cluster. 
print(compute_target.get_status().serialize())

#  Create Experiment
experiment_name = "pytorch-with-mlflow"
mlflow.set_experiment(experiment_name)

# Train model on GPU compute on Azure
env = Environment.get(workspace=ws, name="AzureML-PyTorch-1.4-GPU").clone("mlflow-env")

env.python.conda_dependencies.add_pip_package("azureml-mlflow")
env.python.conda_dependencies.add_pip_package("Pillow==6.0.0")

src = ScriptRunConfig(source_directory="./scripts", script="train.py")
src.run_config.environment = env
src.run_config.target = "gpu-cluster"

from azureml.core import Experiment

exp = Experiment(ws, experiment_name)
run = exp.submit(src)


run.wait_for_completion(show_output=True)

# Deploy model as web service

# Data to be written
deploy_config ={
    "computeType": "aci"
}
# Serializing json 
json_object = json.dumps(deploy_config)
  
# Writing to sample.json
with open("deployment_config.json", "w") as outfile:
    outfile.write(json_object)

# set the tracking uri as the deployment client
client = get_deploy_client(mlflow.get_tracking_uri())

# set the model path 
model_path = "model"

# set the deployment config
deployment_config_path = "deployment_config.json"
test_config = {'deploy-config-file': deployment_config_path}

# define the model path and the name is the service name
# the model gets registered automatically and a name is autogenerated using the "name" parameter below 
client.create_deployment(model_uri='runs:/{}/{}'.format(run.id, model_path),
                         config=test_config,
                         name="pytorch-aci-deployment")